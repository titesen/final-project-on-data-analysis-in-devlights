# üìä Chinook Strategy Command Center

> Soluci√≥n integral de Business Intelligence end-to-end: Data Warehouse, ETL automatizado y visualizaci√≥n interactiva para an√°lisis estrat√©gico de datos de negocio.

![Status](https://img.shields.io/badge/Status-Production-success) 
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue) 
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED) 
![Metabase](https://img.shields.io/badge/Metabase-Latest-509EE3)
![License](https://img.shields.io/badge/License-MIT-green)

## üìë Tabla de Contenidos

- [Descripci√≥n General](#-descripci√≥n-general)
- [Caracter√≠sticas Principales](#-caracter√≠sticas-principales)
- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [Modelo de Datos](#-modelo-de-datos)
  - [Esquema OLTP (Fuente)](#esquema-oltp-fuente)
  - [Esquema OLAP (Data Warehouse)](#esquema-olap-data-warehouse)
- [An√°lisis Implementados](#-an√°lisis-implementados)
  - [Segmentaci√≥n RFM](#segmentaci√≥n-rfm-de-clientes)
  - [KPIs de Negocio](#kpis-de-negocio)
- [Instalaci√≥n y Configuraci√≥n](#-instalaci√≥n-y-configuraci√≥n)
  - [Requisitos Previos](#requisitos-previos)
  - [Pasos de Instalaci√≥n](#pasos-de-instalaci√≥n)
  - [Acceso a Servicios](#acceso-a-servicios)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Stack Tecnol√≥gico](#-stack-tecnol√≥gico)
- [Uso y Operaci√≥n](#-uso-y-operaci√≥n)
- [Troubleshooting](#-troubleshooting)
- [Contribuci√≥n](#-contribuci√≥n)
- [Licencia](#-licencia)
- [Autor](#-autor)

## üéØ Descripci√≥n General

**Chinook Strategy Command Center** es un proyecto de an√°lisis de datos que implementa una soluci√≥n completa de **Business Intelligence (BI)** para transformar datos transaccionales en insights accionables. El proyecto simula un entorno corporativo real de una tienda de medios digitales, abarcando desde la extracci√≥n de datos hasta la visualizaci√≥n interactiva de m√©tricas de negocio.

### Contexto de Negocio

**Chinook** es una tienda global de m√∫sica y video digital con operaciones en m√∫ltiples pa√≠ses. A pesar de contar con un sistema transaccional robusto, la organizaci√≥n enfrentaba desaf√≠os cr√≠ticos:

- **Silos de informaci√≥n**: Datos dispersos en tablas normalizadas sin visi√≥n consolidada.
- **Latencia anal√≠tica**: Consultas complejas degradaban el rendimiento operacional.
- **Ausencia de segmentaci√≥n**: Sin metodolog√≠a para identificar clientes de alto valor o en riesgo de churn.
- **Decisiones reactivas**: Falta de m√©tricas en tiempo real para estrategia comercial.

### Soluci√≥n Implementada

Este proyecto resuelve estos desaf√≠os mediante:

1. **Migraci√≥n OLTP ‚Üí OLAP**: Construcci√≥n de un Data Warehouse optimizado para an√°lisis.
2. **Pipeline ETL automatizado**: Transformaci√≥n y carga de datos sin intervenci√≥n manual al iniciar el contenedor.
3. **Modelo dimensional**: Esquema de estrella (Star Schema) para consultas de alto rendimiento.
4. **Segmentaci√≥n avanzada**: Algoritmo RFM para clasificaci√≥n de clientes directamente en SQL.
5. **Dashboard interactivo**: Visualizaci√≥n en tiempo real con Metabase pre-cargado.
6. **Infraestructura como c√≥digo**: Despliegue reproducible "One-Click" con Docker Compose.

## ‚ú® Caracter√≠sticas Principales

- ‚úÖ **Despliegue automatizado**: Un solo comando (`docker compose up`) levanta toda la infraestructura.
- ‚úÖ **ETL sin c√≥digo**: Scripts SQL ejecutados autom√°ticamente al iniciar.
- ‚úÖ **Pre-configurado**: Dashboard con visualizaciones y conexiones listas para usar.
- ‚úÖ **An√°lisis avanzado**: Segmentaci√≥n RFM, an√°lisis de cohortes, series temporales.
- ‚úÖ **Escalable**: Arquitectura modular basada en microservicios.
- ‚úÖ **Portable**: Funciona en cualquier sistema (Windows, Mac, Linux) con Docker.
- ‚úÖ **Open Source**: Stack tecnol√≥gico completamente libre y gratuito.

## üèóÔ∏è Arquitectura del Sistema

El proyecto implementa una arquitectura de datos moderna basada en contenedores, siguiendo el patr√≥n **ELT (Extract, Load, Transform)**.

### Diagrama de Arquitectura

```mermaid
graph TD
    subgraph Docker_Compose_Network [Docker Compose Network]
        direction TB
        METABASE[Metabase<br/>Port 3000]
        DB[(PostgreSQL 16<br/>Port 5432)]
        PGADMIN[pgAdmin 4<br/>Port 5050]
        
        METABASE -->|Conecta JDBC| DB
        PGADMIN -->|Administra| DB
    end

    subgraph Database_Internal [Dentro de PostgreSQL]
        direction TB
        OLTP[(Esquema OLTP<br/>Source)]
        ETL_PROCESS{Scripts ETL<br/>SQL Automatizado}
        OLAP[(Esquema OLAP<br/>Data Warehouse)]
        
        OLTP -->|Extract| ETL_PROCESS
        ETL_PROCESS -->|Transform & Load| OLAP
    end

    USER((Usuario)) -->|Visualiza| METABASE
    USER -->|Administra| PGADMIN

```

### Componentes

#### 1. Base de Datos PostgreSQL (Contenedor `db`)

* **Imagen**: `postgres:16`
* **Funci√≥n**: Aloja tanto el esquema OLTP (fuente) como el OLAP (Data Warehouse) en la base de datos `chinook`.
* **Inicializaci√≥n**: Ejecuta autom√°ticamente scripts SQL en `/docker-entrypoint-initdb.d/`:
* `01_oltp.sql`: Crea y puebla el esquema transaccional.
* `02_olap.sql`: Crea el esquema dimensional `analytics` y ejecuta transformaciones ETL.


* **Persistencia**: Volumen Docker `postgres_data` para garantizar durabilidad.

#### 2. Metabase (Contenedor `metabase`)

* **Imagen**: `metabase/metabase:latest`
* **Funci√≥n**: Plataforma de BI para visualizaci√≥n interactiva.
* **Configuraci√≥n**: Base de datos H2 embebida restaurada desde backup local.
* **Conectividad**: Se conecta autom√°ticamente al esquema OLAP del contenedor `db`.

#### 3. pgAdmin (Contenedor `pgadmin`)

* **Imagen**: `dpage/pgadmin4:latest`
* **Funci√≥n**: Interfaz web para administraci√≥n de PostgreSQL.
* **Uso**: Inspecci√≥n de esquemas, ejecuci√≥n de queries, debugging.

## üìê Modelo de Datos

### Esquema OLTP (Fuente)

El esquema transaccional sigue la **Tercera Forma Normal (3NF)**, optimizado para integridad referencial y operaciones CRUD.

#### Diagrama OLTP

```mermaid
erDiagram
    Artist ||--|{ Album : "tiene"
    Album ||--|{ Track : "contiene"
    Genre ||--|{ Track : "clasifica"
    MediaType ||--|{ Track : "formato"
    Track ||--|{ InvoiceLine : "en"
    Invoice ||--|{ InvoiceLine : "tiene"
    Customer ||--|{ Invoice : "compra"
    Employee ||--|{ Customer : "soporta"
    Employee ||--|{ Employee : "reporta_a"

    Artist {
        int ArtistId PK
        string Name
    }
    Album {
        int AlbumId PK
        string Title
        int ArtistId FK
    }
    Track {
        int TrackId PK
        string Name
        int AlbumId FK
        int GenreId FK
    }
    Customer {
        int CustomerId PK
        string FirstName
        string LastName
        string Email
    }
    Invoice {
        int InvoiceId PK
        datetime InvoiceDate
        numeric Total
    }

```

**Limitaciones del modelo OLTP para an√°lisis**:

* Requiere 6+ JOINs para consultas anal√≠ticas b√°sicas.
* Alto costo computacional para agregaciones.
* Dise√±ado para escritura (INSERT/UPDATE), no para lectura intensiva.

### Esquema OLAP (Data Warehouse)

El Data Warehouse implementa un **Star Schema** optimizado para consultas anal√≠ticas de alto rendimiento, alojado en el esquema `analytics`.

#### Diagrama OLAP

```mermaid
erDiagram
    fact_sales }|..|| dim_customer : "cliente"
    fact_sales }|..|| dim_track : "producto"
    fact_sales }|..|| dim_employee : "vendedor"
    fact_sales }|..|| dim_date : "fecha"

    fact_sales {
        int sales_key PK
        int quantity
        numeric unit_price
        numeric total_revenue
        int customer_key FK
        int track_key FK
        int date_key FK
    }
    dim_customer {
        int customer_key PK
        string full_name
        string country
        string customer_segment
    }
    dim_track {
        int track_key PK
        string track_name
        string genre_name
        string media_type_name
    }
    dim_date {
        int date_key PK
        int year
        int month
        string is_weekend
    }

```

**Ventajas del modelo OLAP**:

* **Reducci√≥n de JOINs**: De 6+ a 1-2 uniones m√°ximo.
* **Performance**: Consultas dr√°sticamente m√°s r√°pidas.
* **Desnormalizaci√≥n estrat√©gica**: Datos redundantes para acelerar lectura.

## üìä An√°lisis Implementados

### Segmentaci√≥n RFM de Clientes

El proyecto implementa un algoritmo de **RFM (Recency, Frequency, Monetary)** directamente en SQL mediante Window Functions (`NTILE`).

**L√≥gica de Segmentaci√≥n**:

1. **Recencia (R)**: D√≠as desde la √∫ltima compra.
2. **Frecuencia (F)**: Cantidad de facturas √∫nicas.
3. **Monetizaci√≥n (M)**: Total gastado hist√≥rico.

| Segmento | Descripci√≥n | Estrategia Sugerida |
| --- | --- | --- |
| ü•á **Campeones (VIP)** | Score RFM alto (R=5, F=5, M=5) | Programas de fidelidad exclusivos. |
| üíé **Leales Potenciales** | Compran seguido, buen gasto | Upselling y Cross-selling. |
| ‚ö†Ô∏è **En Riesgo** | Gastaban mucho pero no volvieron | Campa√±as de reactivaci√≥n agresivas. |
| üí§ **Perdidos** | Baja frecuencia y recencia | Evaluar costo de retenci√≥n vs adquisici√≥n. |

### KPIs de Negocio

El dashboard implementa los siguientes indicadores clave:

#### KPIs Financieros

| M√©trica | Definici√≥n |
| --- | --- |
| **Total Revenue** | Suma total de facturaci√≥n hist√≥rica. |
| **AOV (Ticket Promedio)** | Ingreso promedio por transacci√≥n √∫nica. |

#### KPIs Operativos

| M√©trica | Definici√≥n |
| --- | --- |
| **Top G√©neros** | G√©neros musicales con mayor volumen de ventas. |
| **Top Pa√≠ses** | Regiones geogr√°ficas con mayor penetraci√≥n de mercado. |
| **Performance Empleados** | Ranking de ventas por agente de soporte. |

## üöÄ Instalaci√≥n y Configuraci√≥n

### Requisitos Previos

Antes de comenzar, aseg√∫rese de tener instalado:

* **Docker**: v20.10 o superior.
* **Docker Compose**: v2.0 o superior (incluido en Docker Desktop).
* **Git**: Para clonar el repositorio.
* **Puertos Libres**: 3000 (Metabase), 5432 (Postgres), 5050 (pgAdmin).

### Pasos de Instalaci√≥n

#### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/devlights-data-analysis-final-project.git
cd devlights-data-analysis-final-project
```

#### 2. Levantar la Infraestructura

Ejecute el siguiente comando en la ra√≠z del proyecto:

```bash
docker compose up -d
```

**¬øQu√© sucede al ejecutar esto?**

1. Descarga las im√°genes de Postgres, Metabase y pgAdmin.
2. Crea la red `chinook_net`.
3. Inicia la base de datos `chinook`.
4. Ejecuta `01_oltp.sql` (Crea tablas fuente).
5. Ejecuta `02_olap.sql` (Crea DW y procesa datos).
6. Inicia Metabase y restaura el dashboard desde el backup local.

> ‚è≥ **Nota**: El primer inicio puede demorar unos 60 segundos mientras se inicializan los servicios.

#### 3. Verificar Estado

```bash
docker compose ps
```

Todos los contenedores (`chinook_db`, `chinook_bi`, `chinook_pgadmin`) deber√≠an estar en estado "Up" o "Running".

### Acceso a Servicios

#### üìä A. Dashboard de Negocio (Metabase)

El sistema ya viene con usuarios y dashboards precargados.

* **URL**: [http://localhost:3000](https://www.google.com/search?q=http://localhost:3000)
* **Email**: `admin@devlights.com`
* **Password**: `helloworld2025`

#### üõ†Ô∏è B. Administraci√≥n de Base de Datos (pgAdmin 4)

Para inspecci√≥n t√©cnica y consultas SQL manuales.

* **URL**: [http://localhost:5050](https://www.google.com/search?q=http://localhost:5050)
* **Email**: `admin@chinook.com`
* **Password**: `root`

**Datos para conectar el servidor (Register Server):**

* **Host name**: `db`
* **Username**: `devlights_user`
* **Password**: `devlights_password`
* **Database**: `chinook`

## üìÅ Estructura del Proyecto

```
devlights-data-analysis-final-project/
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml          # Orquestaci√≥n de contenedores
‚îÇ
‚îú‚îÄ‚îÄ assets/                     # Scripts SQL de inicializaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ 01_oltp.sql             # Script Fuente (OLTP)
‚îÇ   ‚îî‚îÄ‚îÄ 02_olap.sql             # Script Data Warehouse (OLAP + ETL)
‚îÇ
‚îú‚îÄ‚îÄ metabase_backup_data/       # Backup persistente del Dashboard
‚îÇ   ‚îî‚îÄ‚îÄ metabase.db.mv.db       # Base de datos H2 de Metabase
‚îÇ
‚îî‚îÄ‚îÄ README.md                   # Documentaci√≥n del proyecto
```

## üõ†Ô∏è Stack Tecnol√≥gico

| Componente | Tecnolog√≠a | Versi√≥n | Uso |
| --- | --- | --- | --- |
| **Base de Datos** | PostgreSQL | 16 | Motor Relacional & Data Warehouse |
| **Contenedores** | Docker | Latest | Empaquetado y ejecuci√≥n |
| **Orquestaci√≥n** | Docker Compose | v2+ | Gesti√≥n de servicios y redes |
| **Visualizaci√≥n** | Metabase | Latest | Dashboarding y BI |
| **Administraci√≥n** | pgAdmin 4 | Latest | GUI para PostgreSQL |
| **Lenguaje** | SQL (PL/pgSQL) | Standard | L√≥gica de negocio y transformaci√≥n |

## üí° Uso y Operaci√≥n

### Comandos √ötiles

**Detener el entorno (conservando datos):**

```bash
docker compose stop
```

**Reiniciar el entorno:**

```bash
docker compose start
```

**Destruir entorno (BORRA DATOS y vol√∫menes):**

```bash
docker compose down -v
```

*‚ö†Ô∏è √ötil si quieres reiniciar la base de datos desde cero para volver a correr los scripts SQL.*

**Ver logs de la base de datos:**

```bash
docker logs -f chinook_db

```

---

## üîß Troubleshooting

### Problema: "Container chinook_db is unhealthy"

* **Causa**: El script SQL fall√≥ o tard√≥ demasiado.
* **Soluci√≥n**: Revisa los logs con `docker logs chinook_db`. Si hubo un error en los scripts, corrige el SQL y ejecuta `docker compose down -v` seguido de `docker compose up -d`.

### Problema: Metabase pide configuraci√≥n inicial (Setup)

* **Causa**: No ley√≥ correctamente el archivo de backup.
* **Soluci√≥n**: Aseg√∫rate de que la carpeta `metabase_backup_data` contenga el archivo `metabase.db.mv.db` directamente (sin subcarpetas extra) y reinicia el contenedor `chinook_bi`.

### Problema: Puerto ocupado (Bind for 0.0.0.0:3000 failed)

* **Causa**: Otro servicio en tu PC usa el puerto 3000.
* **Soluci√≥n**: Edita `docker-compose.yml` y cambia el mapeo de puertos de Metabase a `"3001:3000"`.

## ü§ù Contribuci√≥n

Las contribuciones son bienvenidas. Para cambios importantes:

1. Fork el repositorio.
2. Crea una rama (`git checkout -b feature/AmazingFeature`).
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`).
4. Push a la rama (`git push origin feature/AmazingFeature`).
5. Abre un Pull Request.

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver archivo `LICENSE` para m√°s detalles.

## üë§ Autor

**Facundo Nicol√°s Gonz√°lez**

* **Proyecto**: Trabajo final Data Analytics - Devlights
* **GitHub**: [@titesen](https://github.com/titesen)
* **LinkedIn**: [Facundo Gonz√°lez](https://www.linkedin.com/in/facundo-n-gonzalez/)

---

*√öltima actualizaci√≥n: Diciembre 2025*